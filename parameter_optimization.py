import json
import time
import numpy as np
import gymnasium as gym
from argparse import Namespace
from agent_dir.agent_dqn import AgentDQN
import matplotlib.pyplot as plt
import os
import itertools
import random as python_random
from gpu_monitor import GPUMonitor


class ParameterOptimizer:
    def __init__(self):
        self.results = []
        self.best_config = None
        self.best_frames = float('inf')
        
        # å®šä¹‰å‚æ•°æœç´¢ç©ºé—´ - é’ˆå¯¹GPUä¼˜åŒ–ï¼Œé¿å…å°æ‰¹æ¬¡é—®é¢˜
        self.param_ranges = {
            'lr': [0.0005, 0.001, 0.002, 0.003, 0.005, 0.008, 0.01],
            'lr_decay': [0.995, 0.997, 0.999, 0.9995, 0.9997, 0.9999],
            'epsilon_decay': [0.995, 0.997, 0.999, 0.9995, 0.9997, 0.9999],
            'batch_size': [64, 128, 256, 512, 1024],  # ç¡®ä¿æœ€å°æ‰¹æ¬¡ä¸º64
            'memory_size': [50000, 100000, 200000, 300000, 500000],
            'update_target_freq': [100, 200, 300, 500, 750, 1000],
            'hidden_size': [256, 512, 1024, 2048],
            'grad_norm_clip': [0.5, 1.0, 2.0, 5.0, 10.0],
            'train_freq': [1, 2, 4],
            'num_layers': [2, 3, 4, 5]
        }
        
        # éšæœºæœç´¢çš„å‚æ•°èŒƒå›´ï¼ˆè¿ç»­å€¼ï¼‰
        self.continuous_ranges = {
            'lr': (0.0001, 0.01),
            'lr_decay': (0.99, 0.9999),
            'epsilon_decay': (0.99, 0.9999),
            'grad_norm_clip': (0.1, 10.0)
        }
        
        # ç¦»æ•£å€¼èŒƒå›´ - GPUä¼˜åŒ–ç‰ˆæœ¬ï¼Œç¡®ä¿æ‰¹æ¬¡å¤§å°è¶³å¤Ÿ
        self.discrete_ranges = {
            'batch_size': [64, 128, 256, 512, 1024, 1536, 2048],  # ç§»é™¤å°æ‰¹æ¬¡
            'memory_size': list(range(50000, 500001, 50000)),
            'update_target_freq': list(range(50, 1001, 50)),
            'hidden_size': [128, 256, 384, 512, 768, 1024, 1536, 2048],
            'train_freq': [1, 2, 4, 8],
            'num_layers': [2, 3, 4, 5, 6]
        }
        
        # GPUç›‘æ§å™¨
        self.gpu_monitor = None

    def create_args(self, **kwargs):
        """åˆ›å»ºå‚æ•°é…ç½®"""
        default_args = {
            'env_name': 'CartPole-v1',  # ä½¿ç”¨v1ç‰ˆæœ¬
            'seed': 11037,
            'hidden_size': 256,  # å¢åŠ é»˜è®¤ç½‘ç»œå¤§å°
            'lr': 0.001,
            'gamma': 0.99,
            'grad_norm_clip': 1.0,
            'lr_decay': 0.9995,
            'lr_min': 0.00005,
            'lr_patience': 50,
            'lr_factor': 0.5,
            'convergence_window': 30,
            'convergence_threshold': 195,
            'convergence_check_interval': 20,
            'test': False,
            'use_cuda': True,
            'n_frames': 60000,
            'train_freq': 1,
            'num_layers': 3,
            'batch_size': 64,  # ç¡®ä¿é»˜è®¤æ‰¹æ¬¡è¶³å¤Ÿå¤§
        }
        
        # æ›´æ–°å‚æ•°
        default_args.update(kwargs)
        
        # ç¡®ä¿æ‰¹æ¬¡å¤§å°è‡³å°‘ä¸º64
        if 'batch_size' in default_args:
            default_args['batch_size'] = max(default_args['batch_size'], 64)
        
        return Namespace(**default_args)

    def generate_random_params(self):
        """ç”Ÿæˆéšæœºå‚æ•°ç»„åˆ"""
        params = {}
        
        # è¿ç»­å‚æ•°
        for param, (min_val, max_val) in self.continuous_ranges.items():
            if param in ['lr_decay', 'epsilon_decay']:
                # å¯¹äºè¡°å‡å‚æ•°ï¼Œä½¿ç”¨å¯¹æ•°ç©ºé—´é‡‡æ ·
                log_min = np.log10(1 - max_val)
                log_max = np.log10(1 - min_val)
                decay_factor = 1 - 10**(np.random.uniform(log_min, log_max))
                params[param] = decay_factor
            else:
                # å¯¹äºå­¦ä¹ ç‡ï¼Œä½¿ç”¨å¯¹æ•°ç©ºé—´
                if param == 'lr':
                    params[param] = 10**(np.random.uniform(np.log10(min_val), np.log10(max_val)))
                else:
                    params[param] = np.random.uniform(min_val, max_val)
        
        # ç¦»æ•£å‚æ•°
        for param, values in self.discrete_ranges.items():
            params[param] = python_random.choice(values)
        
        return params
    
    def grid_search_small(self):
        """å°è§„æ¨¡ç½‘æ ¼æœç´¢ - ä¿®å¤æ‰¹æ¬¡å¤§å°é—®é¢˜"""
        print("æ‰§è¡Œå°è§„æ¨¡ç½‘æ ¼æœç´¢...")
        
        # é€‰æ‹©è¾ƒå°‘çš„å‚æ•°å€¼è¿›è¡Œç½‘æ ¼æœç´¢ï¼Œç¡®ä¿æ‰¹æ¬¡å¤§å°è¶³å¤Ÿ
        small_ranges = {
            'lr': [0.001, 0.003, 0.005],
            'batch_size': [64, 128, 256],  # ç§»é™¤32
            'hidden_size': [128, 256, 512],  # è°ƒæ•´èŒƒå›´
            'update_target_freq': [200, 400, 600]
        }
        
        # ç”Ÿæˆæ‰€æœ‰ç»„åˆ
        param_names = list(small_ranges.keys())
        param_values = list(small_ranges.values())
        
        total_combinations = np.prod([len(values) for values in param_values])
        print(f"æ€»å…± {total_combinations} ä¸ªå‚æ•°ç»„åˆ")
        
        for i, combination in enumerate(itertools.product(*param_values)):
            params = dict(zip(param_names, combination))
            config_name = f"Grid_{i+1:03d}"
            
            print(f"\nè¿›åº¦: {i+1}/{total_combinations}")
            self.test_configuration(config_name, **params)
    
    def random_search(self, n_trials=50):
        """éšæœºæœç´¢"""
        print(f"æ‰§è¡Œéšæœºæœç´¢ ({n_trials} æ¬¡è¯•éªŒ)...")
        
        for i in range(n_trials):
            params = self.generate_random_params()
            config_name = f"Random_{i+1:03d}"
            
            print(f"\nè¿›åº¦: {i+1}/{n_trials}")
            self.test_configuration(config_name, **params)
    
    def adaptive_search(self, n_trials=30):
        """è‡ªé€‚åº”æœç´¢ï¼šåŸºäºå½“å‰æœ€ä½³ç»“æœè¿›è¡Œå±€éƒ¨æœç´¢"""
        print(f"æ‰§è¡Œè‡ªé€‚åº”æœç´¢ ({n_trials} æ¬¡è¯•éªŒ)...")
        
        if not self.best_config:
            print("æ²¡æœ‰åŸºç¡€é…ç½®ï¼Œå…ˆæ‰§è¡Œéšæœºæœç´¢...")
            self.random_search(10)
        
        for i in range(n_trials):
            if self.best_config:
                # åŸºäºæœ€ä½³é…ç½®è¿›è¡Œæ‰°åŠ¨
                params = self.perturb_best_params()
            else:
                # å¦‚æœè¿˜æ²¡æœ‰æœ€ä½³é…ç½®ï¼Œä½¿ç”¨éšæœºæœç´¢
                params = self.generate_random_params()
            
            config_name = f"Adaptive_{i+1:03d}"
            print(f"\nè¿›åº¦: {i+1}/{n_trials}")
            self.test_configuration(config_name, **params)
    
    def perturb_best_params(self):
        """åŸºäºæœ€ä½³å‚æ•°è¿›è¡Œæ‰°åŠ¨"""
        best_params = self.best_config['params'].copy()
        params = {}
        
        for param_name, current_value in best_params.items():
            if param_name in self.continuous_ranges:
                min_val, max_val = self.continuous_ranges[param_name]
                # åœ¨å½“å‰å€¼é™„è¿‘è¿›è¡Œæ‰°åŠ¨
                noise_factor = 0.2  # 20%çš„æ‰°åŠ¨
                if param_name == 'lr':
                    # å¯¹æ•°ç©ºé—´æ‰°åŠ¨
                    log_current = np.log10(current_value)
                    log_noise = np.random.normal(0, noise_factor)
                    new_value = 10**(log_current + log_noise)
                    params[param_name] = np.clip(new_value, min_val, max_val)
                else:
                    noise = np.random.normal(0, (max_val - min_val) * noise_factor)
                    params[param_name] = np.clip(current_value + noise, min_val, max_val)
            
            elif param_name in self.discrete_ranges:
                values = self.discrete_ranges[param_name]
                current_idx = values.index(current_value) if current_value in values else 0
                # åœ¨é™„è¿‘ç´¢å¼•ä¸­é€‰æ‹©
                nearby_range = 3
                start_idx = max(0, current_idx - nearby_range)
                end_idx = min(len(values), current_idx + nearby_range + 1)
                params[param_name] = python_random.choice(values[start_idx:end_idx])
            else:
                params[param_name] = current_value
        
        return params
    
    def test_configuration(self, config_name, **params):
        """æµ‹è¯•å•ä¸ªå‚æ•°é…ç½®"""
        print(f"æµ‹è¯•é…ç½®: {config_name}")
        print(f"å‚æ•°: {params}")
        
        # å¯åŠ¨GPUç›‘æ§
        self.gpu_monitor = GPUMonitor()
        self.gpu_monitor.start_monitoring()
        
        try:
            # åˆ›å»ºç¯å¢ƒå’Œä»£ç†
            env = gym.make('CartPole-v1')  # ä½¿ç”¨v1ç‰ˆæœ¬
            args = self.create_args(**params)
            
            agent = AgentDQN(env, args)
            
            # è®¾ç½®æ‰€æœ‰å‚æ•°åˆ°agentä¸­
            for param_name, param_value in params.items():
                if hasattr(agent, param_name):
                    setattr(agent, param_name, param_value)
            
            # ç‰¹æ®Šå¤„ç†éœ€è¦é‡æ–°åˆå§‹åŒ–çš„å‚æ•°
            if 'batch_size' in params:
                agent.batch_size = max(params['batch_size'], 64)  # ç¡®ä¿æœ€å°64
            if 'memory_size' in params:
                agent.memory_size = params['memory_size']
                agent.memory = agent.ReplayBuffer(params['memory_size'])
            if 'update_target_freq' in params:
                agent.update_target_freq = params['update_target_freq']
            if 'train_freq' in params:
                agent.train_freq = params['train_freq']
            if 'num_layers' in params or 'hidden_size' in params:
                # é‡æ–°æ„å»ºç½‘ç»œä»¥æ”¯æŒæ›´å¤šå±‚
                agent.rebuild_network(
                    hidden_size=params.get('hidden_size', agent.hidden_size),
                    num_layers=params.get('num_layers', 3)
                )
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            # è¿è¡Œè®­ç»ƒ
            converged, frames_used = self.run_training(agent)
            
            # è®°å½•ç»“æŸæ—¶é—´
            end_time = time.time()
            training_time = end_time - start_time
            
            # åœæ­¢ç›‘æ§å¹¶è·å–ç»Ÿè®¡
            self.gpu_monitor.stop_monitoring()
            gpu_stats = self.gpu_monitor.get_current_stats()
            
            # ä¿å­˜ç»“æœ
            result = {
                'config_name': config_name,
                'params': params,
                'converged': converged,
                'frames_used': frames_used,
                'training_time': training_time,
                'success': converged and frames_used < self.best_frames,
                'gpu_stats': gpu_stats  # æ·»åŠ GPUç»Ÿè®¡ä¿¡æ¯
            }
            
            self.results.append(result)
            
            # æ‰“å°GPUåˆ©ç”¨ç‡ä¿¡æ¯
            if gpu_stats:
                print(f"GPUåˆ©ç”¨ç‡: å¹³å‡{gpu_stats['avg_gpu_usage']:.1f}%, æœ€å¤§{gpu_stats['max_gpu_usage']:.1f}%")
                print(f"GPUæ˜¾å­˜: å¹³å‡{gpu_stats['avg_gpu_memory']:.1f}%, æœ€å¤§{gpu_stats['max_gpu_memory']:.1f}%")
            
            if converged and frames_used < self.best_frames:
                self.best_frames = frames_used
                self.best_config = result
                print(f"ğŸ‰ æ–°çš„æœ€ä½³é…ç½®ï¼ä½¿ç”¨å¸§æ•°: {frames_used}")
                # ä¿å­˜å½“å‰æœ€ä½³é…ç½®
                self.save_best_config_immediately()
            
            # æ¸…ç†
            agent.writer.close()
            env.close()
            
            return result
            
        except Exception as e:
            if self.gpu_monitor:
                self.gpu_monitor.stop_monitoring()
            print(f"âŒ é…ç½®æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {
                'config_name': config_name,
                'params': params,
                'converged': False,
                'frames_used': float('inf'),
                'training_time': 0,
                'success': False,
                'error': str(e)
            }
    
    def save_best_config_immediately(self):
        """ç«‹å³ä¿å­˜å½“å‰æœ€ä½³é…ç½®"""
        if self.best_config:
            os.makedirs('optimization_results', exist_ok=True)
            with open('optimization_results/current_best.json', 'w', encoding='utf-8') as f:
                json.dump(self.best_config, f, indent=2, ensure_ascii=False)
    
    def run_training(self, agent):
        """è¿è¡Œè®­ç»ƒå¹¶æ£€æµ‹æ”¶æ•›"""
        all_rewards = []
        
        while agent.frame_count < agent.n_frames:
            state = agent.env.reset()[0]
            episode_reward = 0
            done = False
            
            while not done:
                action = agent.make_action(state, test=False)
                next_state, reward, terminated, truncated, _ = agent.env.step(action)
                done = terminated or truncated
                
                agent.memory.push(state, action, reward, next_state, done)
                state = next_state
                episode_reward += reward
                agent.frame_count += 1
                
                if agent.frame_count % 2 == 0 and len(agent.memory) >= agent.batch_size:
                    agent.train()
                
                if agent.frame_count % agent.update_target_freq == 0:
                    agent.target_network.load_state_dict(agent.q_network.state_dict())
                
                if done:
                    break
            
            all_rewards.append(episode_reward)
            agent.episode_count += 1
            
            # æ£€æŸ¥æ”¶æ•›
            if agent.episode_count % agent.convergence_check_interval == 0:
                is_converged, mean_reward = agent.check_convergence(all_rewards)
                if is_converged:
                    print(f"âœ… æ”¶æ•›ï¼å›åˆ: {agent.episode_count}, å¸§æ•°: {agent.frame_count}, å¹³å‡å¥–åŠ±: {mean_reward:.2f}")
                    return True, agent.frame_count
        
        # æœªæ”¶æ•›
        print(f"âŒ æœªæ”¶æ•›ï¼Œè¾¾åˆ°æœ€å¤§å¸§æ•°: {agent.frame_count}")
        return False, agent.frame_count
    
    def optimize(self, method='all'):
        """æ‰§è¡Œå‚æ•°ä¼˜åŒ–"""
        print("å¼€å§‹ç³»ç»ŸåŒ–å‚æ•°ä¼˜åŒ–...")
        
        if method == 'all' or method == 'grid':
            self.grid_search_small()
        
        if method == 'all' or method == 'random':
            self.random_search(n_trials=30)
        
        if method == 'all' or method == 'adaptive':
            self.adaptive_search(n_trials=20)
    
    def save_results(self):
        """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
        os.makedirs('optimization_results', exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        with open('optimization_results/detailed_results.json', 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜æœ€ä½³é…ç½®
        if self.best_config:
            with open('optimization_results/best_config.json', 'w', encoding='utf-8') as f:
                json.dump(self.best_config, f, indent=2, ensure_ascii=False)
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
    
    def generate_report(self):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        report = []
        report.append("å‚æ•°ä¼˜åŒ–æŠ¥å‘Š")
        report.append("="*50)
        report.append(f"æ€»æµ‹è¯•é…ç½®æ•°: {len(self.results)}")
        
        # ç»Ÿè®¡æˆåŠŸç‡
        successful_configs = [r for r in self.results if r.get('converged', False)]
        success_rate = len(successful_configs) / len(self.results) * 100
        report.append(f"æ”¶æ•›æˆåŠŸç‡: {success_rate:.1f}%")
        
        if successful_configs:
            # æœ€ä½³é…ç½®
            report.append(f"\næœ€ä½³é…ç½® (æœ€å°‘å¸§æ•°: {self.best_frames}):")
            report.append(f"é…ç½®åç§°: {self.best_config['config_name']}")
            report.append(f"è®­ç»ƒæ—¶é—´: {self.best_config['training_time']:.2f}ç§’")
            report.append("å‚æ•°è®¾ç½®:")
            for key, value in self.best_config['params'].items():
                report.append(f"  {key}: {value}")
            
            # æ‰€æœ‰æˆåŠŸé…ç½®æ’åº
            successful_configs.sort(key=lambda x: x['frames_used'])
            report.append(f"\næ‰€æœ‰æˆåŠŸé…ç½® (æŒ‰å¸§æ•°æ’åº):")
            for i, config in enumerate(successful_configs, 1):
                report.append(f"{i}. {config['config_name']}: {config['frames_used']} å¸§ "
                            f"({config['training_time']:.1f}ç§’)")
        
        # å¤±è´¥é…ç½®
        failed_configs = [r for r in self.results if not r.get('converged', False)]
        if failed_configs:
            report.append(f"\nå¤±è´¥é…ç½®:")
            for config in failed_configs:
                reason = config.get('error', 'æœªæ”¶æ•›')
                report.append(f"- {config['config_name']}: {reason}")
        
        # ä¿å­˜æŠ¥å‘Š
        with open('optimization_results/optimization_report.txt', 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))
        
        # æ‰“å°æŠ¥å‘Š
        print('\n'.join(report))
    
    def plot_results(self):
        """ç»˜åˆ¶ä¼˜åŒ–ç»“æœå›¾è¡¨"""
        if not self.results:
            return
        
        successful_configs = [r for r in self.results if r.get('converged', False)]
        if not successful_configs:
            return
        
        plt.figure(figsize=(12, 8))
        
        # å¸§æ•°å¯¹æ¯”
        plt.subplot(2, 2, 1)
        names = [r['config_name'] for r in successful_configs]
        frames = [r['frames_used'] for r in successful_configs]
        plt.bar(range(len(names)), frames)
        plt.xticks(range(len(names)), names, rotation=45)
        plt.ylabel('ä½¿ç”¨å¸§æ•°')
        plt.title('å„é…ç½®æ”¶æ•›æ‰€éœ€å¸§æ•°')
        
        # è®­ç»ƒæ—¶é—´å¯¹æ¯”
        plt.subplot(2, 2, 2)
        times = [r['training_time'] for r in successful_configs]
        plt.bar(range(len(names)), times)
        plt.xticks(range(len(names)), names, rotation=45)
        plt.ylabel('è®­ç»ƒæ—¶é—´ (ç§’)')
        plt.title('å„é…ç½®è®­ç»ƒæ—¶é—´')
        
        # æ•ˆç‡å¯¹æ¯” (å¸§æ•°/æ—¶é—´)
        plt.subplot(2, 2, 3)
        efficiency = [f/t for f, t in zip(frames, times)]
        plt.bar(range(len(names)), efficiency)
        plt.xticks(range(len(names)), names, rotation=45)
        plt.ylabel('å¸§æ•°/ç§’')
        plt.title('è®­ç»ƒæ•ˆç‡å¯¹æ¯”')
        
        # å­¦ä¹ ç‡å¯¹æ¯”
        plt.subplot(2, 2, 4)
        lrs = [r['params'].get('lr', 0) for r in successful_configs]
        plt.scatter(lrs, frames)
        plt.xlabel('å­¦ä¹ ç‡')
        plt.ylabel('ä½¿ç”¨å¸§æ•°')
        plt.title('å­¦ä¹ ç‡ vs æ”¶æ•›å¸§æ•°')
        
        plt.tight_layout()
        plt.savefig('optimization_results/optimization_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def analyze_parameter_importance(self):
        """åˆ†æå‚æ•°é‡è¦æ€§"""
        if not self.results:
            return
        
        successful_configs = [r for r in self.results if r.get('converged', False)]
        if len(successful_configs) < 3:
            return
        
        # åˆ†ææ¯ä¸ªå‚æ•°ä¸æ€§èƒ½çš„å…³ç³»
        param_analysis = {}
        
        for param_name in self.param_ranges.keys():
            param_values = []
            frame_counts = []
            
            for config in successful_configs:
                if param_name in config['params']:
                    param_values.append(config['params'][param_name])
                    frame_counts.append(config['frames_used'])
            
            if len(param_values) > 2:
                correlation = np.corrcoef(param_values, frame_counts)[0, 1]
                param_analysis[param_name] = {
                    'correlation': correlation,
                    'best_value': param_values[np.argmin(frame_counts)],
                    'avg_value': np.mean(param_values),
                    'std_value': np.std(param_values)
                }
        
        # ä¿å­˜åˆ†æç»“æœ
        os.makedirs('optimization_results', exist_ok=True)
        with open('optimization_results/parameter_analysis.json', 'w', encoding='utf-8') as f:
            json.dump(param_analysis, f, indent=2, ensure_ascii=False)
        
        return param_analysis


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    parser = argparse.ArgumentParser(description='å‚æ•°ä¼˜åŒ–å·¥å…·')
    parser.add_argument('--method', choices=['all', 'grid', 'random', 'adaptive'], 
                       default='all', help='ä¼˜åŒ–æ–¹æ³•')
    parser.add_argument('--trials', type=int, default=30, help='éšæœºæœç´¢è¯•éªŒæ¬¡æ•°')
    args = parser.parse_args()
    
    optimizer = ParameterOptimizer()
    
    try:
        if args.method == 'random':
            optimizer.random_search(n_trials=args.trials)
        elif args.method == 'adaptive':
            optimizer.adaptive_search(n_trials=args.trials)
        else:
            optimizer.optimize(method=args.method)
        
        optimizer.save_results()
        optimizer.plot_results()
        optimizer.analyze_parameter_importance()
        
        print(f"\nğŸ‰ å‚æ•°ä¼˜åŒ–å®Œæˆï¼")
        if optimizer.best_config:
            print(f"æœ€ä½³é…ç½®ä½¿ç”¨å¸§æ•°: {optimizer.best_frames}")
            print(f"è¯¦ç»†ç»“æœä¿å­˜åœ¨: optimization_results/")
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ”¶æ•›çš„é…ç½®")
            
    except KeyboardInterrupt:
        print("\nâš ï¸ ä¼˜åŒ–è¢«ç”¨æˆ·ä¸­æ–­")
        optimizer.save_results()
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
        optimizer.save_results()


if __name__ == '__main__':
    main()
